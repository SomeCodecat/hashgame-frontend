name: Build and deploy frontend to GitHub Pages (static-only)

on:
  workflow_dispatch:
  push:
    branches: [main]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: Scrape latest data
        run: |
          python scrape_hash_h10a.py

      - name: Prepare deploy directory
        run: |
          rm -rf out
          mkdir out
          # Use static page (not React frontend for now)
          cp -a static/. out/
          # Copy the scraped state.json to be available at /state
          if [ -f data/state.json ]; then
            cp data/state.json out/state.json
          fi

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./out

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
